#!/usr/bin/env python
#
#    Copyright 2017 EPAM Systems
#
#    Licensed under the Apache License, Version 2.0 (the "License");
#    you may not use this file except in compliance with the License.
#    You may obtain a copy of the License at
#
#        http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS,
#    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#    See the License for the specific language governing permissions and
#    limitations under the License.
#

try:
    import docker_bootup
except ImportError:
    pass

import sys
import os
import argparse
import logging

from drun.serving.pyserve import serve_model
from drun.edi.deploy import \
    build_model, \
    deploy_model, undeploy_model, inspect, \
    deploy_kubernetes, undeploy_kubernetes, scale_kubernetes, inspect_kubernetes, \
    VALID_SERVING_WORKERS
import drun.utils

ROOT_LOGGER = logging.getLogger()

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='DRun Command-Line Interface')
    parser.add_argument('--verbose',
                        help='verbose log output',
                        action='store_true')
    subparsers = parser.add_subparsers()

    # --------- LOCAL DOCKER SECTION -----------
    build_parser = subparsers.add_parser('build', description='build model into new docker image')
    build_parser.add_argument('model_file',
                              type=str, help='serialized model file name')
    build_parser.add_argument('--model_id',
                              type=str, help='alpha-numeric identifier of the model to publish (for overriding)')
    build_parser.add_argument('--model-type',
                              type=str, help='drun-python, tensorflow, mleap',
                              default='drun-python')
    build_parser.add_argument('--python-package',
                              type=str, help='path to drun-python package wheel')
    build_parser.add_argument('--base-docker-image',
                              type=str, help='base docker image for new image')
    build_parser.add_argument('--docker-image-tag',
                              type=str, help='docker image tag')
    build_parser.add_argument('--push-to-registry',
                              type=str, help='docker registry address')
    build_parser.add_argument('--with-deploy',
                              action='store_true', help='deploy after build')
    build_parser.add_argument('--serving',
                              default=VALID_SERVING_WORKERS[0],
                              type=str, help='serving worker: %s' % ', '.join(VALID_SERVING_WORKERS))
    build_parser.set_defaults(func=build_model)

    deploy_parser = subparsers.add_parser('deploy-local',
                                          description='deploys a model into a new container (local docker)')
    deploy_parser.add_argument('--model-id',
                               type=str, help='model id')
    deploy_parser.add_argument('--docker-image',
                               type=str, help='docker sha256 image')
    deploy_parser.add_argument('--docker-network',
                               type=str, help='docker network')
    deploy_parser.add_argument('--grafana-server',
                               type=str, help='Grafana server')
    deploy_parser.add_argument('--grafana-user',
                               type=str, help='Grafana user')
    deploy_parser.add_argument('--grafana-password',
                               type=str, help='Grafana password')
    deploy_parser.add_argument('--expose-model-port',
                               type=int, help='Expose model at specific port')
    deploy_parser.set_defaults(func=deploy_model)

    undeploy_parser = subparsers.add_parser('undeploy-local',
                                            description='kills all containers service the model (local docker)')
    undeploy_parser.add_argument('model_id',
                                 type=str, help='identifier of the model')
    undeploy_parser.add_argument('--docker-network',
                                 type=str, help='docker network')
    undeploy_parser.add_argument('--grafana-server',
                                 type=str, help='Grafana server')
    undeploy_parser.add_argument('--grafana-user',
                                 type=str, help='Grafana user')
    undeploy_parser.add_argument('--grafana-password',
                                 type=str, help='Grafana password')
    undeploy_parser.set_defaults(func=undeploy_model)

    inspect_parser = subparsers.add_parser('inspect-local',
                                           description='get information about docker network state')
    inspect_parser.add_argument('--docker-network',
                                type=str, help='docker network')
    inspect_parser.set_defaults(func=inspect)

    # --------- KUBERNETES SECTION -----------
    deploy_k8s_parser = subparsers.add_parser('deploy',
                                              description='deploys a model into a kubernetes cluster')
    deploy_k8s_parser.add_argument('image',
                                   type=str, help='docker image')
    deploy_k8s_parser.add_argument('--image-for-k8s',
                                   type=str, help='docker image for kubernetes deployment')
    deploy_k8s_parser.add_argument('--scale',
                                   default=1,
                                   type=int, help='count of instances')
    deploy_k8s_parser.add_argument('--namespace',
                                   default='default',
                                   type=str, help='kubernetes namespace')
    deploy_k8s_parser.add_argument('--deployment',
                                   default='drun',
                                   type=str, help='kubernetes namespace')
    deploy_k8s_parser.add_argument('--text-output',
                                   action='store_true', help='just output deployment configuration')
    deploy_k8s_parser.set_defaults(func=deploy_kubernetes)

    inspect_k8s_parser = subparsers.add_parser('inspect',
                                               description='get information about currently deployed models')
    inspect_k8s_parser.add_argument('--namespace',
                                    default='default',
                                    type=str, help='kubernetes namespace')
    inspect_k8s_parser.set_defaults(func=inspect_kubernetes)

    scale_k8s_parser = subparsers.add_parser('scale',
                                             description='change count of model pods')
    scale_k8s_parser.add_argument('model_id',
                                  type=str, help='docker image')
    scale_k8s_parser.add_argument('scale',
                                  type=int, help='new count of replicas')
    scale_k8s_parser.add_argument('--namespace',
                                  default='default',
                                  type=str, help='kubernetes namespace')
    scale_k8s_parser.set_defaults(func=scale_kubernetes)

    undeploy_k8s_parser = subparsers.add_parser('undeploy',
                                                description='undeploy model deployment')
    undeploy_k8s_parser.add_argument('model_id',
                                     type=str, help='docker image')
    undeploy_k8s_parser.add_argument('--namespace',
                                     default='default',
                                     type=str, help='kubernetes namespace')
    undeploy_k8s_parser.add_argument('--grace-period',
                                     default=0,
                                     type=int, help='removal grace period')
    undeploy_k8s_parser.set_defaults(func=undeploy_kubernetes)

    # --------- SERVING SECTION -----------
    pyserve_parser = subparsers.add_parser('pyserve', description='serve a python model')
    pyserve_parser.add_argument('--model_file',
                                type=str)
    pyserve_parser.add_argument('--model-id',
                                type=str)
    pyserve_parser.add_argument('--consul-addr',
                                type=str, help='Consul Agent IP address')
    pyserve_parser.add_argument('--consul-port',
                                type=int, help='Consul Agent port')
    pyserve_parser.add_argument('--legion-addr',
                                type=str)
    pyserve_parser.add_argument('--legion-port',
                                type=int)
    pyserve_parser.add_argument('--debug',
                                type=drun.utils.string_to_bool)
    pyserve_parser.add_argument('--register-on-consul',
                                type=drun.utils.string_to_bool)
    pyserve_parser.add_argument('--legion-autodiscover',
                                type=drun.utils.string_to_bool)
    pyserve_parser.set_defaults(func=serve_model)

    pyserve_parser = subparsers.add_parser('pyserve-dummy', description='serve a dummy python model using flask')
    pyserve_parser.add_argument('--consul-addr',
                                type=str, help='Consul Agent IP address')
    pyserve_parser.add_argument('--consul-port',
                                type=int, help='Consul Agent port')
    pyserve_parser.add_argument('--legion-addr',
                                type=str)
    pyserve_parser.add_argument('--legion-port',
                                type=int)
    pyserve_parser.set_defaults(func=serve_model)

    # --------- END OF SECTIONS -----------
    args = parser.parse_args(sys.argv[1:])

    v = vars(args)

    if args.verbose or drun.utils.string_to_bool(os.getenv('VERBOSE', '')):
        log_level = logging.DEBUG
    else:
        log_level = logging.ERROR

    ROOT_LOGGER.setLevel(log_level)

    if 'func' in v:
        args.func(args)
    else:
        parser.print_help()
        sys.exit(1)
